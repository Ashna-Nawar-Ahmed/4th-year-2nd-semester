{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 06 - Sentence Representation (NLP).ipynb","provenance":[{"file_id":"16M9jk-y9Jv_7A0aCeR8Lu5TbXeZaI3SF","timestamp":1614805147806},{"file_id":"1oRR5fqjRnqsFc4rbaomukmuJCHODZt4T","timestamp":1594281753600},{"file_id":"1RdJzNfgb12DK_1ApTQMuuadN2qKGn62A","timestamp":1594044077293},{"file_id":"18EWHIgdF_IrZy41jNslWpWs9zh_DvBl-","timestamp":1594027294645}],"collapsed_sections":[],"authorship_tag":"ABX9TyPepHdG7jImxd3wUgtOZ4VG"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bUMBAY99VlXW"},"source":["## Word Embedding \n","\n","**All texts need to be converted to numbers before starts processing by\n","the machine. Specifically, vectors of numbers.**\n","\n","**Text is messy in nature** and machine learning algorithms prefer well defined **fixed-length inputs and outputs**.\n","\n","**Word Embedding** is one such technique where we can represent the text using vectors. Before deep learning era, the popular forms of word embeddings were:\n","\n","- **BoW**, which stands for Bag of Words\n","- **TF-IDF**, which stands for Term Frequency-Inverse Document Frequency\n","\n","### Bag-of-Words (BoW)\n","\n","The **Bag-of-Words (BoW)**  model is a way of representing text data when modeling text with machine learning algorithms. The **Bag-of-Words (BoW)** model is popular, simple to understand, and has seen great success in **language modeling** and **document classification**.\n","\n","A bag-of-words is a representation of text that describes the occurrence of words within a document. **It involves two things:**\n","\n","- A vocabulary of known words.\n","- A measure of the presence of known words.\n","\n","### Example (BoW)\n","\n","Consider the following 4 sentences:- \n","\n","- It was the best of times.\n","- it was the worst of Times.\n","- it is the time of stupidity.\n","- it is the age of foolishness.\n","\n","Form this above example, let’s consider each line as a separate **“document”** and the 4 lines as our entire corpus of documents.\n","\n","\n","### Vocabulary \n","\n","What would be the total vocabulary???\n"]},{"cell_type":"markdown","metadata":{"id":"nd2qNqKacxgI"},"source":["## Bag of Words (BoW) Model\n","\n","### 1. Design the Vocabulary\n","\n","The unique words by **ignoring case, punctuations, and making them into root words** are:\n","\n","1. it\n","2. was\n","3. the \n","4. best\n","5. of\n","6. time\n","7. worst\n","8. stupidity\n","9. is \n","10. age\n","11. foolishness\n","\n","**Vocabulary contains 11 words while the full corpus contains 24 words.**\n","\n","### 2. Create Document Vectors\n","\n","The objective is to **turn each document of text into a vector** so that we can use as input or output for a machine learning model.\n","\n","Because we know the vocabulary has 11 words, we can use a fixed-length document representation of 11, with one position in the vector to score each word. The simplest scoring method is to mark the presence of words as a boolean value, 0 for absent, 1 for present. There can be other methods such as count based methods of the terms if more than one occurance of a trem.\n","\n","In this example the **binary vector of four documents** would look as follows:\n","\n","|                | it | was | the | best | of | time | worst | stupidity | is | age | foolishness |\n","|:--------------:|:--:|:---:|:---:|:----:|:--:|:----:|:-----:|:------:|:--:|:---:|:-----------:|\n","| Document #1 [ It was the best of times. ] |  1 |  1  |  1  |   1  |  1 |   1  |   0   |    0   |  0 |  0  |      0      |\n","| Document #2 [ it was the worst of Times. ] |  1 |  1  |  1  |   0  |  1 |   1  |   1   |    0   |  0 |  0  |      0      |\n","| Document #3 [ it is the time of stupidity. ] |  1 |  0  |  1  |   0  |  1 |   1  |   0   |    1   |  1 |  0  |      0      |\n","| Document #4 [ it is the age of foolishness. ] |  1 |  0  |  1  |   0  |  1 |   0  |   0   |    0   |  1 |  1  |      1      |\n","\n","### Problems \n","\n","- Ordering of words have been discarded which **ignores the context**. These unordered words **can't preserve document semantics** For instance, **“this is interesting”** vs **“is this interesting”**. Moreover, **\"stupidity\"** and **\"foolishness\"** are considered two different words in the dictionary. \n","- We are retaining no information on the **grammar of the sentences**.\n","- New documents that overlap with the vocabulary of known words, but may contain **words outside of the vocabulary**.\n","- If the vocabulary size increases the **document representation dimension** also increases. "]},{"cell_type":"markdown","metadata":{"id":"u3XeSWGTmEEQ"},"source":["## Managing Vocabulary\n","\n","In the previous example, the **length of the document vector** is equal to the number of known words which is 11 words. \n","\n","For a very large corpus, such as thousands of books, the length of the vector **might be thousands or millions of positions**. Further, each document may contain **very few of the known words in the vocabulary**. This results in a vector with **lots of zero scores, called a sparse vector or sparse representation**. Sparse vectors require more memory and computational resources **(space and time complexity)** \n","\n","It's very important to **decrease the size of the vocabulary** when using a bag-of-words model.\n","\n","### Solution #1\n","\n","There are simple text cleaning techniques that can be used as a first step, such as:\n","\n","- Ignoring case\n","- Ignoring punctuation\n","- Ignoring frequent words that don’t contain much information, called stop words, like “a,” “of,” etc.\n","- Fixing misspelled words.\n","- Reducing words to their stem (e.g. “play” from “playing”) using stemming algorithms.\n","- Can use lemmatization \n","\n","### Solution #2\n","\n","Each word or token is called a “gram”. Creating a vocabulary of two-word pairs is, in turn, called a **bigram model**.\n","\n","An **N-gram** is an N-token sequence of words: a 2-gram (more commonly called a bigram) is a two-word sequence of words like “please turn”, “turn your”, or “your homework”, and a **3-gram (more commonly called a trigram)** is a three-word sequence of words like “please turn your”, or “turn your homework”.\n","\n","For example, the bigrams in the first line of text in the previous section: **“It was the best of times”** are as follows:\n","\n","- “it was”\n","- “was the”\n","- “the best”\n","- “best of”\n","- “of times”\n","\n","**A vocabulary then tracks triplets of words is called a trigram model** and the general approach is called the **n-gram model**, where n refers to the number of grouped words. \n","\n","**Note: Often a simple bigram approach is better than a 1-gram bag-of-words model.** \n","\n"]},{"cell_type":"markdown","metadata":{"id":"lmOYcFk2Bm9d"},"source":["## One-Hot Representation\n","\n","The one­ hot representation, as the name suggests, starts with a zero vector, and sets as 1 the corresponding entry in the vector if the word is present in the sentence or document. \n","\n","Tokenizing the sentences, ignoring punctuation, and treating everything as lowercase, will yield a vocabulary of size 8: `{time, fruit, flies, like, a, an, arrow, banana}`. \n","\n","The binary encoding for **“like a banana”** would then be: \n","\n","```\n","[0, 0, 0, 1, 1, 0, 0, 1]\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"jQBGhETP9vBe","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"ok","timestamp":1614847531763,"user_tz":-360,"elapsed":867,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"3366cfce-b6e6-4044-aa88-75fbd1889385"},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","import seaborn as sns\n","\n","corpus = ['Time flies flies Like an arrow.',\n","          'Fruit flies like a banana.']\n","\n","one_hot_vectorizer = CountVectorizer(binary=True)\n","one_hot = one_hot_vectorizer.fit_transform(corpus).toarray()\n","\n","print (one_hot)\n","\n","print (one_hot_vectorizer.vocabulary_)\n","\n","dictionary = sorted(one_hot_vectorizer.vocabulary_)\n","\n","print(dictionary)\n","\n","sns.heatmap(one_hot, annot=True, cbar=False, xticklabels=dictionary,\n","                                             yticklabels=['Sentence 1','Sentence 2'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[1 1 0 1 0 1 1]\n"," [0 0 1 1 1 1 0]]\n","{'time': 6, 'flies': 3, 'like': 5, 'an': 0, 'arrow': 1, 'fruit': 4, 'banana': 2}\n","['an', 'arrow', 'banana', 'flies', 'fruit', 'like', 'time']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f137db0f910>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"8mjEcnd4vnu9"},"source":["\\\n","\n","### **Term Frequency (TF)**\n","Term Frequent (**TF**) is a measure of how frequently a term, $t$, appears in a document, $d$:\n","\n","\\\n","\n","$$TF_{t,d} = \\frac{n_{t,d}}{\\text{Total number of terms in document}\\ d }$$\n","\n","\\\n","\n","$n_{t,d}$ = Number of times term $t$ appears in a document $d$. Thus, each document and term would have its own **TF** value.\n","\n","Consider these 3 documents like **BoW** model:- \n","\n","- It was the best of the time.\n","- it was the worst of Times.\n","- it is the time of stupidity.\n","\n","The vocabulary or dictionary of the entire corpus would be:- \n","\n","1. it\n","2. was\n","3. the \n","4. best\n","5. of\n","6. time\n","7. worst\n","8. is\n","9. stupidity\n","\n","Now we will calculate the **TF** values for the **Document 3**. \n","\n","Document 3 :- **it is the time of stupidity.**\n","\n","- Number of words in Document 3 = **6**\n","- TF for the word **‘the’** = (number of times **‘the’** appears in Document 3) / (number of terms in Document 3) = **1/6**\n","\n","Likewise:- \n","\n","- TF(**'it'**) = 1/6\n","- TF(**'was'**) = 0/6 = 0\n","- TF(**'the'**) = 1/6 \n","- TF(**'best'**) = 0/6 = 0\n","- TF(**'of'**) = 1/6 \n","- TF(**'time'**) = 1/6\n","- TF(**'worst'**) = 0/6 = 0\n","- TF(**'is'**) = 1/6\n","- TF(**'stupidity'**) = 1/6\n","\n","We can calculate all the term frequencies for all the terms of all the documents in this manner:-\n","\n","|    Term   | Document#1 | Document#2 | Document#3 | TF (Document#1) | TF (Document#2) | TF (Document#3) |\n","|:---------:|:----------:|:----------:|:----------:|:---------------:|:---------------:|:---------------:|\n","|     it    |      1     |      1     |      1     |       1/7       |       1/6       |       1/6       |\n","|    was    |      1     |      1     |      0     |       1/7       |       1/6       |        0        |\n","|    the    |      2     |      1     |      1     |       2/7       |       1/6       |       1/6       |\n","|    best   |      1     |      0     |      0     |       1/7       |        0        |        0        |\n","|     of    |      1     |      1     |      1     |       1/7       |       1/6       |       1/6       |\n","|    time   |      1     |      1     |      1     |       1/7       |       1/6       |       1/6       |\n","|   worst   |      0     |      1     |      0     |        0        |       1/6       |        0        |\n","|    is     |      0     |      0     |      1     |        0        |        0        |       1/6       |\n","| stupidity |      0     |      0     |      1     |        0        |        0        |       1/6       |\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"8fmAnU-0wLxw","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1594283730453,"user_tz":-360,"elapsed":876,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"df9f711d-e97c-4f47-ae24-99433051c736"},"source":["import math\n","\n","print(math.log((3),10))\n","\n","print(math.log((330),10))\n","\n","print(math.log((3/3),10))\n","\n","print(math.log((4/3),10))\n","\n","print(math.log((4/5),10))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.47712125471966244\n","2.518513939877887\n","0.0\n","0.1249387366082999\n","-0.09691001300805638\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZwShhL2IA80C"},"source":["\\\n","\n","### **Inverse Document Frequency (IDF)**\n","\n","IDF is a measure of how important a term is. We need the IDF value because computing just the **TF alone is not sufficient** to understand the importance of words:\n","\n","\\\n","\n","$$IDF_{t} = log \\ (\\frac{\\text{Total Number of Documents}}{\\text{The Number of Documents with Term $t$}})$$\n","\n","\\\n","\n","A problem with scoring word frequency is that highly frequent words **(‘is’, ‘the’, ‘a’ etc)** start to dominate in the document (e.g. larger score), but may not contain as much **“useful information”** to the model comapre to the rarer but **domain specific words**.\n","\n","\n","One approach is to rescale the frequency of words by **how often they appear in all documents**, so that the scores for frequent words like “the” that are also frequent **across all documents are penalized**.\n","\n","This approach to scoring is called **Term Frequency – Inverse Document Frequency, or TF-IDF** for short, where:\n","\n","- **Term Frequency:** is a scoring of the frequency of the word in the current document.\n","- **Inverse Document Frequency:** is a scoring of how rare the word is across documents.\n","\n","**Thus the idf of a rare term is high, whereas the idf of a frequent term is likely to be low.**\n","\n","We can calculate the IDF values for **Document 3**:\n","\n","Document 3 :- **it is the time of stupidity.**\n","\n","IDF(‘it’) =  log(total number of documents/number of documents containing the word ‘it’) = log(3/3) = log(1) = 0\n","\n","We can calculate the IDF values for each word like this. Thus, the IDF values for the entire vocabulary would be:\n","\n","|    Term   | Document#1 | Document#2 | Document#3 |  IDF |\n","|:---------:|:----------:|:----------:|:----------:|:----:|\n","|     it    |      1     |      1     |      1     | 0.00 |\n","|    was    |      1     |      1     |      0     | 0.18 |\n","|    the    |      2     |      1     |      1     | 0.00 |\n","|    best   |      1     |      0     |      0     | 0.48 |\n","|     of    |      1     |      1     |      1     | 0.00 |\n","|    time   |      1     |      1     |      1     | 0.00 |\n","|   worst   |      0     |      1     |      0     | 0.48 |\n","|    is     |      0     |      0     |      1     | 0.48 |\n","| stupidity |      0     |      0     |      1     | 0.48 |\n","\n","\\\n","\n","We can now compute the TF-IDF score for each word in the corpus. Words with a higher score are more important, and those with a lower score are less important:\n","\n","$$(TF-IDF)_{t,d} = TF_{t,d} * IDF_{t}$$\n","\n","\n","You can find the overall summary in the following figure.\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1Xw5RlK_RxYtZEQtpFNaePXnJNyQmLcn1\" width=\"680\" height=\"230\">\n","</div>\n","\n","\n","\n","We can now calculate the TF-IDF score for every word in **Document 3**:\n","\n","Document 3 :- **it is the time of stupidity.**\n","\n","TF-IDF(‘it’, Document 3) = TF(‘it’, Document 3) * IDF(‘it’) = 1/6 * 0 = 0\n","\n","Likewise:- \n","\n","- TF-IDF(**'it'**) = (1/6) * 0 = 0\n","- TF-IDF(**'is'**) = (1/6) * 0.48\n","- TF-IDF(**'the'**) = (1/6) * 0 = 0\n","- TF-IDF(**'best'**) = (0/6) * 0.48 = 0\n","- TF-IDF(**'time'**) = (1/6) * 0 = 0\n","- TF-IDF(**'of'**) = (1/6) * 0 = 0\n","- TF-IDF(**'stupidity'**) = (1/6) * 0.48 \n","\n","Similarly, we can calculate the TF-IDF scores for all the words with respect to all the documents.\n","\n","- **First,** notice how if there is a very common\n","word that occurs in all documents (i.e., n = N), IDF(w) is 0 and the TF­-IDF score is 0, thereby\n","completely penalizing that term. \n","- **Second,** if a term occurs very rarely, perhaps in only one document,\n","the IDF will be the maximum possible value, log N\n"]},{"cell_type":"code","metadata":{"id":"fenTEvLMcQjj","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"ok","timestamp":1614818050382,"user_tz":-360,"elapsed":928,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"404de899-67a6-48c2-a39e-2b1fc1443cde"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import seaborn as sns\n","\n","corpus = ['Time flies flies like an arrow.',\n","          'Fruit flies like a banana.']\n","\n","tfidf_vectorizer = TfidfVectorizer()\n","tfidf = tfidf_vectorizer.fit_transform(corpus).toarray()\n","\n","print (tfidf)\n","\n","print (tfidf_vectorizer.vocabulary_)\n","\n","dictionary = sorted(tfidf_vectorizer.vocabulary_)\n","\n","print(dictionary)\n","\n","sns.heatmap(tfidf, annot=True, cbar=False, xticklabels=dictionary,\n","                                           yticklabels=['Sentence 1','Sentence 2'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.42519636 0.42519636 0.         0.60506143 0.         0.30253071\n","  0.42519636]\n"," [0.         0.         0.57615236 0.40993715 0.57615236 0.40993715\n","  0.        ]]\n","{'time': 6, 'flies': 3, 'like': 5, 'an': 0, 'arrow': 1, 'fruit': 4, 'banana': 2}\n","['an', 'arrow', 'banana', 'flies', 'fruit', 'like', 'time']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f90fd08ad10>"]},"metadata":{"tags":[]},"execution_count":2},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"z8lmJxHdUkQ_"},"source":["### Summary\n","\n","- Bag of Words just creates a set of vectors containing the count of word occurrences in the document, while the TF-IDF model contains information on the more important words and the less important ones as well.\n","\n","- **Bag of Words vectors are easy to interpret. However, TF-IDF usually performs better in machine / deep learning models.**\n","\n","- Understanding the context of words is important. Detecting the similarity between the words **‘time’** and **‘age’**, or **'stupidity'** and **'foolishness'**.\n","\n","- This is where Word Embedding techniques such as **Word2Vec, Continuous Bag of Words (CBOW), Skipgram**, etc come into play."]},{"cell_type":"markdown","metadata":{"id":"ldSJsxgTaNQG"},"source":["## Bag-of-Words Text Classification\n","\n","We will show how to build a simple **Bag of Words (BoW)** text classifier using PyTorch. The classifier is trained on **IMDB movie reviews dataset**."]},{"cell_type":"code","metadata":{"id":"DxbiSycDaVra"},"source":["from pathlib import Path\n","\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjcmgT59vmrL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614818207278,"user_tz":-360,"elapsed":1012,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"aae24015-1606-4c3c-9a30-74522ad465f0"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"PmcpVQ_7adaz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614818245127,"user_tz":-360,"elapsed":2157,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"ec25a591-ff9e-4896-f8ac-5eb3c6b260fe"},"source":["DATA_PATH = 'datasets/imdb.csv'\n","if not Path(DATA_PATH).is_file():\n","    gdd.download_file_from_google_drive(\n","        file_id='1nEqdpGkMhAPDWZn4oij5o1Irf4T8PxvF',\n","        dest_path=DATA_PATH,\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading 1nEqdpGkMhAPDWZn4oij5o1Irf4T8PxvF into datasets/imdb.csv... Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WG5a0eI4bKMe","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1614818303617,"user_tz":-360,"elapsed":859,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"5e803b0a-6297-4c33-9bfd-a763738f1c8d"},"source":["# View some example records\n","pd.read_csv(DATA_PATH).sample(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A very, very, very slow-moving, aimless movie about a distressed, drifting young man.</th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>827</th>\n","      <td>Juano Hernandez (an exceptional actor who play...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>772</th>\n","      <td>The movie in movie situations in the beginning...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>845</th>\n","      <td>Great character actors Telly Savalas and Peter...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>903</th>\n","      <td>I'm so sorry but I really can't recommend it t...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>382</th>\n","      <td>The sets (especially designed to work with the...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    A very, very, very slow-moving, aimless movie about a distressed, drifting young man.    0\n","827  Juano Hernandez (an exceptional actor who play...                                       1\n","772  The movie in movie situations in the beginning...                                       1\n","845  Great character actors Telly Savalas and Peter...                                       1\n","903  I'm so sorry but I really can't recommend it t...                                       0\n","382  The sets (especially designed to work with the...                                       1"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"GFHFNXnTosld"},"source":["## Bag-of-Words Sentiment Classification\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1DpUpmKZGNAtoY7FH7PNKbZK-0FukGuuM\" width=\"390\" height=\"360\">\n","</div>\n","\n","So the final bag-of-words vector for `['the', 'gray', 'cat', 'sat', 'on', 'the', 'gray', 'mat']` is `[0, 1, 1, 2, 2, 1, 0, 1]`"]},{"cell_type":"code","metadata":{"id":"pY5h7gotsHRF"},"source":["class Sequences(Dataset):\n","    def __init__(self, data):\n","        self.vectorizer = CountVectorizer(stop_words='english')\n","        self.sequences = self.vectorizer.fit_transform(data.review.tolist())\n","        self.labels = data.label.tolist()\n","        self.token2idx = self.vectorizer.vocabulary_\n","        self.idx2token = {idx: token for token, idx in self.token2idx.items()}\n","    \n","    def __getitem__(self, i):\n","        return self.sequences[i, :].toarray(), self.labels[i]\n","    \n","    def __len__(self):\n","        return self.sequences.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxmg5kkfsXzx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614819125506,"user_tz":-360,"elapsed":848,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"3c1151ce-6642-4316-e36f-5f79d47b56b6"},"source":["df = pd.read_csv(DATA_PATH, header=None)\n","\n","print(len(df))\n","\n","df.columns = [\"review\", \"label\"]\n","\n","df_train = df.head(900)\n","df_test = df.tail(100)\n","\n","dataset = Sequences(df_train)\n","\n","train_loader = DataLoader(dataset, batch_size=900)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"onjnJ4DSwKKM"},"source":["class BagOfWordsClassifier(nn.Module):\n","    def __init__(self, vocab_size, hidden1, hidden2):\n","        super().__init__()\n","        ### 1st hidden layer: vocab_size --> 128\n","        self.linear_1 = nn.Linear(vocab_size, hidden1)\n","        ### Non-linearity in 1st hidden layer\n","        self.relu_1 = nn.ReLU()\n","        \n","        ### 2nd hidden layer: 128 --> 64\n","        self.linear_2 = nn.Linear(hidden1, hidden2)\n","        ### Non-linearity in 2nd hidden layer\n","        self.relu_2 = nn.ReLU()\n","        \n","        ### Output layer: 64 --> 1\n","        self.linear_out = nn.Linear(hidden2, 1)\n","        \n","    def forward(self, inputs):\n","        ### 1st hidden layer\n","        out = self.linear_1(inputs.squeeze(1).float())\n","        ### Non-linearity in 1st hidden layer\n","        out = self.relu_1(out)\n","        \n","        ### 2nd hidden layer\n","        out = self.linear_2(out)\n","        ### Non-linearity in 2nd hidden layer\n","        out = self.relu_2(out)\n","        \n","        # Linear layer (output)\n","        logits  = self.linear_out(out)\n","        \n","        return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tNF7hhnBwezw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614819206742,"user_tz":-360,"elapsed":836,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"20bf22a3-8f15-4e77-97af-ef82335039c0"},"source":["model = BagOfWordsClassifier(len(dataset.token2idx), 128, 64)\n","model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BagOfWordsClassifier(\n","  (linear_1): Linear(in_features=2624, out_features=128, bias=True)\n","  (relu_1): ReLU()\n","  (linear_2): Linear(in_features=128, out_features=64, bias=True)\n","  (relu_2): ReLU()\n","  (linear_out): Linear(in_features=64, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"sQMZsHtSwxj_"},"source":["criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9ccPB4Mw2th","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614819244504,"user_tz":-360,"elapsed":17913,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"bcf76cc5-967a-481d-becc-138fd79bf185"},"source":["\n","train_losses = []\n","\n","for epoch in range(150):\n","    losses = []\n","    total = 0\n","    for inputs, target in train_loader:\n","        model.zero_grad()\n","\n","        output = model(inputs)\n","        loss = criterion(output.squeeze(), target.float())\n","        \n","        loss.backward()\n","          \n","        optimizer.step()\n","        \n","        losses.append(loss.item())\n","        total += 1\n","    \n","    epoch_loss = sum(losses) / total\n","    train_losses.append(epoch_loss)\n","        \n","    print(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch #1\tTrain Loss: 0.694\n","Epoch #2\tTrain Loss: 0.691\n","Epoch #3\tTrain Loss: 0.689\n","Epoch #4\tTrain Loss: 0.686\n","Epoch #5\tTrain Loss: 0.682\n","Epoch #6\tTrain Loss: 0.678\n","Epoch #7\tTrain Loss: 0.674\n","Epoch #8\tTrain Loss: 0.669\n","Epoch #9\tTrain Loss: 0.662\n","Epoch #10\tTrain Loss: 0.656\n","Epoch #11\tTrain Loss: 0.648\n","Epoch #12\tTrain Loss: 0.639\n","Epoch #13\tTrain Loss: 0.629\n","Epoch #14\tTrain Loss: 0.619\n","Epoch #15\tTrain Loss: 0.607\n","Epoch #16\tTrain Loss: 0.594\n","Epoch #17\tTrain Loss: 0.580\n","Epoch #18\tTrain Loss: 0.566\n","Epoch #19\tTrain Loss: 0.550\n","Epoch #20\tTrain Loss: 0.533\n","Epoch #21\tTrain Loss: 0.515\n","Epoch #22\tTrain Loss: 0.497\n","Epoch #23\tTrain Loss: 0.478\n","Epoch #24\tTrain Loss: 0.458\n","Epoch #25\tTrain Loss: 0.438\n","Epoch #26\tTrain Loss: 0.417\n","Epoch #27\tTrain Loss: 0.396\n","Epoch #28\tTrain Loss: 0.375\n","Epoch #29\tTrain Loss: 0.354\n","Epoch #30\tTrain Loss: 0.333\n","Epoch #31\tTrain Loss: 0.313\n","Epoch #32\tTrain Loss: 0.293\n","Epoch #33\tTrain Loss: 0.274\n","Epoch #34\tTrain Loss: 0.255\n","Epoch #35\tTrain Loss: 0.238\n","Epoch #36\tTrain Loss: 0.221\n","Epoch #37\tTrain Loss: 0.205\n","Epoch #38\tTrain Loss: 0.191\n","Epoch #39\tTrain Loss: 0.177\n","Epoch #40\tTrain Loss: 0.164\n","Epoch #41\tTrain Loss: 0.152\n","Epoch #42\tTrain Loss: 0.141\n","Epoch #43\tTrain Loss: 0.130\n","Epoch #44\tTrain Loss: 0.121\n","Epoch #45\tTrain Loss: 0.112\n","Epoch #46\tTrain Loss: 0.104\n","Epoch #47\tTrain Loss: 0.097\n","Epoch #48\tTrain Loss: 0.091\n","Epoch #49\tTrain Loss: 0.084\n","Epoch #50\tTrain Loss: 0.079\n","Epoch #51\tTrain Loss: 0.074\n","Epoch #52\tTrain Loss: 0.069\n","Epoch #53\tTrain Loss: 0.065\n","Epoch #54\tTrain Loss: 0.061\n","Epoch #55\tTrain Loss: 0.058\n","Epoch #56\tTrain Loss: 0.054\n","Epoch #57\tTrain Loss: 0.051\n","Epoch #58\tTrain Loss: 0.049\n","Epoch #59\tTrain Loss: 0.046\n","Epoch #60\tTrain Loss: 0.044\n","Epoch #61\tTrain Loss: 0.042\n","Epoch #62\tTrain Loss: 0.040\n","Epoch #63\tTrain Loss: 0.038\n","Epoch #64\tTrain Loss: 0.036\n","Epoch #65\tTrain Loss: 0.035\n","Epoch #66\tTrain Loss: 0.033\n","Epoch #67\tTrain Loss: 0.032\n","Epoch #68\tTrain Loss: 0.030\n","Epoch #69\tTrain Loss: 0.029\n","Epoch #70\tTrain Loss: 0.028\n","Epoch #71\tTrain Loss: 0.027\n","Epoch #72\tTrain Loss: 0.026\n","Epoch #73\tTrain Loss: 0.025\n","Epoch #74\tTrain Loss: 0.024\n","Epoch #75\tTrain Loss: 0.023\n","Epoch #76\tTrain Loss: 0.023\n","Epoch #77\tTrain Loss: 0.022\n","Epoch #78\tTrain Loss: 0.021\n","Epoch #79\tTrain Loss: 0.020\n","Epoch #80\tTrain Loss: 0.020\n","Epoch #81\tTrain Loss: 0.019\n","Epoch #82\tTrain Loss: 0.019\n","Epoch #83\tTrain Loss: 0.018\n","Epoch #84\tTrain Loss: 0.018\n","Epoch #85\tTrain Loss: 0.017\n","Epoch #86\tTrain Loss: 0.017\n","Epoch #87\tTrain Loss: 0.016\n","Epoch #88\tTrain Loss: 0.016\n","Epoch #89\tTrain Loss: 0.015\n","Epoch #90\tTrain Loss: 0.015\n","Epoch #91\tTrain Loss: 0.015\n","Epoch #92\tTrain Loss: 0.014\n","Epoch #93\tTrain Loss: 0.014\n","Epoch #94\tTrain Loss: 0.014\n","Epoch #95\tTrain Loss: 0.013\n","Epoch #96\tTrain Loss: 0.013\n","Epoch #97\tTrain Loss: 0.013\n","Epoch #98\tTrain Loss: 0.012\n","Epoch #99\tTrain Loss: 0.012\n","Epoch #100\tTrain Loss: 0.012\n","Epoch #101\tTrain Loss: 0.012\n","Epoch #102\tTrain Loss: 0.011\n","Epoch #103\tTrain Loss: 0.011\n","Epoch #104\tTrain Loss: 0.011\n","Epoch #105\tTrain Loss: 0.011\n","Epoch #106\tTrain Loss: 0.011\n","Epoch #107\tTrain Loss: 0.010\n","Epoch #108\tTrain Loss: 0.010\n","Epoch #109\tTrain Loss: 0.010\n","Epoch #110\tTrain Loss: 0.010\n","Epoch #111\tTrain Loss: 0.010\n","Epoch #112\tTrain Loss: 0.009\n","Epoch #113\tTrain Loss: 0.009\n","Epoch #114\tTrain Loss: 0.009\n","Epoch #115\tTrain Loss: 0.009\n","Epoch #116\tTrain Loss: 0.009\n","Epoch #117\tTrain Loss: 0.009\n","Epoch #118\tTrain Loss: 0.009\n","Epoch #119\tTrain Loss: 0.008\n","Epoch #120\tTrain Loss: 0.008\n","Epoch #121\tTrain Loss: 0.008\n","Epoch #122\tTrain Loss: 0.008\n","Epoch #123\tTrain Loss: 0.008\n","Epoch #124\tTrain Loss: 0.008\n","Epoch #125\tTrain Loss: 0.008\n","Epoch #126\tTrain Loss: 0.008\n","Epoch #127\tTrain Loss: 0.007\n","Epoch #128\tTrain Loss: 0.007\n","Epoch #129\tTrain Loss: 0.007\n","Epoch #130\tTrain Loss: 0.007\n","Epoch #131\tTrain Loss: 0.007\n","Epoch #132\tTrain Loss: 0.007\n","Epoch #133\tTrain Loss: 0.007\n","Epoch #134\tTrain Loss: 0.007\n","Epoch #135\tTrain Loss: 0.007\n","Epoch #136\tTrain Loss: 0.006\n","Epoch #137\tTrain Loss: 0.006\n","Epoch #138\tTrain Loss: 0.006\n","Epoch #139\tTrain Loss: 0.006\n","Epoch #140\tTrain Loss: 0.006\n","Epoch #141\tTrain Loss: 0.006\n","Epoch #142\tTrain Loss: 0.006\n","Epoch #143\tTrain Loss: 0.006\n","Epoch #144\tTrain Loss: 0.006\n","Epoch #145\tTrain Loss: 0.006\n","Epoch #146\tTrain Loss: 0.006\n","Epoch #147\tTrain Loss: 0.006\n","Epoch #148\tTrain Loss: 0.005\n","Epoch #149\tTrain Loss: 0.005\n","Epoch #150\tTrain Loss: 0.005\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"If94hZmkyPv3"},"source":["def predict_sentiment(text):\n","  test_vector = torch.LongTensor(dataset.vectorizer.transform([text]).toarray())\n","  \n","  output = model(test_vector)\n","  \n","  prediction = torch.sigmoid(output).item()\n","  \n","  if prediction > 0.5:\n","    print(f'{prediction:0.3}: Positive sentiment')\n","    return 1\n","  else:\n","    print(f'{prediction:0.3}: Negative sentiment')\n","    return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6WguymwyRI4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614819370954,"user_tz":-360,"elapsed":601,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"db10df91-c0a7-42d8-edcc-d7c6afd9aa90"},"source":["test_text = \"The story itself is just predictable and lazy.\"\n","predict_sentiment(test_text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.00173: Negative sentiment\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"sp0y6FGpyfLs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614819373806,"user_tz":-360,"elapsed":883,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"e5ffe299-6f8f-4f3d-b888-445cc6fba62f"},"source":["test_text = \"Excellent cast, story line, performances.\"\n","predict_sentiment(test_text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.0: Positive sentiment\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"Wy-rgsfnxBtB"},"source":["## Confusion Matrix for Binary Classification\r\n","\r\n","<div align=\"center\">\r\n","<img src=\"https://drive.google.com/uc?id=13brssGoI1ixObagNFyD60vTdO0dAlN5h\" width=\"600\" height=\"350\">\r\n","</div>\r\n","\r\n","\r\n","- **True Positive (TP):** It refers to the number of predictions where the classifier correctly predicts the positive class as positive.\r\n","- **True Negative (TN):** It refers to the number of predictions where the classifier correctly predicts the negative class as negative.\r\n","- **False Positive (FP):** It refers to the number of predictions where the classifier incorrectly predicts the negative class as positive.\r\n","- **False Negative (FN):** It refers to the number of predictions where the classifier incorrectly predicts the positive class as negative."]},{"cell_type":"code","metadata":{"id":"OKOTAy4r4hN9"},"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kc0mUdNw4h0X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614822803190,"user_tz":-360,"elapsed":856,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"d30d73e4-6f33-4c4c-9ac8-462fd48c30a6"},"source":["pred_labels = []\n","\n","sentences = list(df_test['review'])\n","labels = df_test['label']\n","\n","print(sentences)\n","\n","for sentence in sentences:\n","  pred_labels.append(predict_sentiment(sentence))\n","\n","# accuracy: (tp + tn) / (p + n)\n","accuracy = accuracy_score(labels, pred_labels)\n","print('Accuracy: %f' % accuracy)\n","\n","# precision tp / (tp + fp)\n","precision = precision_score(labels, pred_labels)\n","print('Precision: %f' % precision)\n","\n","# recall: tp / (tp + fn)\n","recall = recall_score(labels, pred_labels)\n","print('Recall: %f' % recall)\n","\n","# f1: 2 tp / (2 tp + fp + fn)\n","f1 = f1_score(labels, pred_labels)\n","print('F1 score: %f' % f1)\n","\n","# confusion matrix\n","matrix = confusion_matrix(labels, pred_labels)\n","print(matrix)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[\"Otherwise, don't even waste your time on this.  \", 'This one just fails to create any real suspense.  ', \"As for the killer, don't expect anything original or even remotely frightening.  \", 'There is, however, some pretty good acting (at least, for this type of film).  ', \"I'm so sorry but I really can't recommend it to anyone.  \", 'One of the most boring,pointless movies I have ever seen.  ', 'The secondary plot line is incomprehensible and its relation to the primary plot line is mystifying.  ', 'Hated it.  ', 'This is one of the worst Sandra Bullock movie since Speed 2 But not quite that bad.  ', \"I don't understand how this garbage got on the shelves of the movie store, it's not even a real movie!  \", 'I highly doubt that anyone could ever like this trash.  ', 'This is not movie-making.  ', \"The acting is like watching wooden puppets moving around and reading from a book, that's how bad it is.  \", 'So I am here to warn you--DO NOT RENT THIS MOVIE, it is the dumbest thing you have never seen!  ', 'I saw this short film on HBO the other day and absolutely loved it.  ', \"I didn't realize how wonderful the short really is until the last two scenes.  \", 'Excellent short film.  ', 'Hopefully, the director James Cox can turn the short into a feature length film with the same cast, or win us over with a whole new film.  ', 'I agree with Jessica, this movie is pretty bad.  ', 'Characters are one-dimensional, even the good guys and especially the bad guys.  ', 'The story line is totally predictable.  ', 'Not much dialogue, not much music, the whole film was shot as elaborately and aesthetically like a sculpture.  ', \"I've seen soap operas more intelligent than this movie.  \", 'Bad characters, bad story and bad acting.  ', 'Really awful.  ', 'Not easy to watch.  ', \"Funny, clever, hip - just like Pray's previous film, Hype!  \", \"It was a long time that i didn't see a so charismatic actor on screen.  \", 'Paolo Sorrentino has written a wonderful story about loneliness and Tony has built one of the most unforgettable characters seen in movies in recent years.  ', \"The movie is not completely perfect but 'Titta Di Girolamo' will stay with you for a long time after the vision of the movie.  \", 'I rate this movie 9/10.  ', \"I do not know if this was Emilio Estevez's directorial debut, but the pacing, the interplay and development of the characters as well as some clever camera work surrounding the character Estevez plays all suggest a natural eye.  \", 'The interplay between Martin and Emilio contains the same wonderful chemistry we saw in Wall Street with Martin and Charlie.  ', 'Kathy Bates is wonderful in her characters subtle desperation and escapism; a variation on her character in \"At Play In The Fields Of The Lord\".  ', \"For readers who have already seen one of Miyazaki's films: he is still in top form and made another worthwhile experience.  \", 'It never condescends, all the characters have good genuine hearts and believable problems.  ', 'The two main characters may be two of the most believable children I ever saw put on screen.  ', 'They are so easy to love, but even more easy to identify with.  ', 'This movie is great--especially if you enjoy visual arts.  ', 'The scenery that the two daughters paint and photograph are beautiful.  ', 'The story is also both funny and poignant at times.  ', 'People who like European films and \"art movies\" will like this movie.  ', 'This is truly an art movie--it actually has a lot of art in it.  ', 'Go rent it.  ', 'However, after finally watching this film, I realized that not only had I had a closed mind to the brilliance it depicts, I also found myself watching it over and over again.  ', \"It's the one movie that never ceases to interest me, simply because it keeps me alert, as I try to attempt to decipher it's meanings.  \", 'Brilliance indeed.  ', \"But if you liked movies like The Matrix (and better yet, their sequels) I think you'll appreciate the thought provoking, mindblowing experience this film will give you.  \", 'Think of the film being like a dream.  ', 'Simply beautiful.  ', \"Both Rickman and Stowe play their roles to the hilt in this tale of a childrens' book writer who-- maybe?-- has written a subversive tract.  \", \"It's a gloriously fun, fast paced and fairly accurate portrayal of the night of a raver.  \", 'It presents a idyllic yet serious portrayal of the ups and downs of the characters lives.  ', 'Just whatever you do, avoid \"Groove\" as its the antithesis of all that is good about Human Traffic.  ', \"It's too bad that everyone else involved didn't share Crowe's level of dedication to quality, for if they did, we'd have a far better film on our hands than this sub-par mess.  \", 'The movie seemed a little slow at first.  ', 'But it picked up speed and got right to the point.  ', 'It showed exactly how the government and the scientist argued for humanity and the reasons of the \"gadget\".  ', 'I enjoyed it.  ', 'I have recommended it to friends.  ', 'I was particularly pleased with the acting ability of Dwight Schultz.  ', 'Both actors truly understand and become their particular character, delivering a convincing, sincere performance.  ', 'Their on-screen chemistry, critical to the entire film, is genuine.  ', \"The film's dialogue is natural, real to life.  \", 'The writer, Gorman Bechard, undoubtedly did his homework because all references are industry and character-age appropriate.  ', 'The incredible soundtrack truly captures the essence of the film.  ', 'Each track commands sentiment, actually contributing to the scenes and characters.  ', \"Definitely worth seeing¬Ö it's the sort of thought provoking film that forces you to question your own threshold of loneliness.  \", 'Hayao Miyazaki\\'s latest and eighth film for Studio Ghibili, \"Gake No Ue No Ponyo\" (Ponyo on the Cliff by the Sea) is a wonderfully fun and imaginative look at childhood.  ', \"At a time when it seems that film animation has been dominated by Disney/Pixar's CGI masterpieces, it is both refreshing and comforting to know that Miyazaki is still relying on traditional hand-drawn animation to tell his charming and enchanting stories.  \", 'Enough can not be said of the remarkable animation in this film.  ', 'The art style has the appearance of crayon/pencil drawings and is wonderfully colorful and fanciful.  ', \"If you act in such a film, you should be glad that you're gonna drift away from earth as far as possible!  \", 'This one wants to surf on the small wave of space movies in 1998 (Deep Impact and Armageddon), and this one fails everywhere.  ', \"If you haven't choked in your own vomit by the end (by all the cheap drama and worthless dialogue) you've must have bored yourself to death with this waste of time.  \", 'Still, it makes up for all of this with a super ending that depicts a great sea vessel being taken out by the mighty frost.  ', 'Just consider the excellent story, solid acting and look of the film as added bonuses.  ', 'Instead, we got a bore fest about a whiny, spoiled brat babysitting.  ', 'Then I watched it again two Sundays ago (March 20th, 2005) and I began to really enjoy it and this time I taped the entire thing.  ', 'It is a very well acted and done TV Movie.  ', 'Judith Light is one of my favorite actresses and I think she does a superb job in this film!  ', 'I keep watching it over and over.  ', \"It's a sad movie, but very good.  \", 'If you have not seen this movie, I definitely recommend it!  ', 'She is as lovely as usual, this cutie!  ', \"Still it's quite interesting and entertaining to follow.  \", ';) Recommend with confidence!  ', 'This movie is well-balanced with comedy and drama and I thoroughly enjoyed myself.  ', \"It was a riot to see Hugo Weaving play a sex-obsessed gay real estate salesman who uses his clients' houses for his trysts with the flaming Darren (Tom Hollander).  \", ':) Anyway, the plot flowed smoothly and the male-bonding scenes were a hoot.  ', 'The opening sequence of this gem is a classic, and the cat n mouse games that follow are a delight to watch.  ', 'Fans of the genre will be in heaven.  ', 'Lange had become a great actress.  ', 'It looked like a wonderful story.  ', 'I never walked out of a movie faster.  ', 'I just got bored watching Jessice Lange take her clothes off!  ', \"Unfortunately, any virtue in this film's production work was lost on a regrettable script.  \", 'In a word, it is embarrassing.  ', 'Exceptionally bad!  ', \"All in all its an insult to one's intelligence and a huge waste of money.  \"]\n","0.00357: Negative sentiment\n","0.00706: Negative sentiment\n","0.00111: Negative sentiment\n","0.741: Positive sentiment\n","0.182: Negative sentiment\n","0.000128: Negative sentiment\n","0.000439: Negative sentiment\n","0.204: Negative sentiment\n","6.23e-05: Negative sentiment\n","0.301: Negative sentiment\n","0.963: Positive sentiment\n","0.774: Positive sentiment\n","0.17: Negative sentiment\n","0.00272: Negative sentiment\n","1.0: Positive sentiment\n","0.249: Negative sentiment\n","0.941: Positive sentiment\n","0.153: Negative sentiment\n","0.0529: Negative sentiment\n","0.029: Negative sentiment\n","0.998: Positive sentiment\n","0.754: Positive sentiment\n","0.112: Negative sentiment\n","4.92e-05: Negative sentiment\n","0.0113: Negative sentiment\n","0.993: Positive sentiment\n","0.00386: Negative sentiment\n","0.188: Negative sentiment\n","0.967: Positive sentiment\n","0.82: Positive sentiment\n","0.958: Positive sentiment\n","1.0: Positive sentiment\n","0.999: Positive sentiment\n","1.0: Positive sentiment\n","0.631: Positive sentiment\n","0.0518: Negative sentiment\n","1.0: Positive sentiment\n","0.997: Positive sentiment\n","0.902: Positive sentiment\n","0.995: Positive sentiment\n","0.121: Negative sentiment\n","1.0: Positive sentiment\n","1.0: Positive sentiment\n","0.22: Negative sentiment\n","0.982: Positive sentiment\n","0.957: Positive sentiment\n","0.98: Positive sentiment\n","1.0: Positive sentiment\n","0.997: Positive sentiment\n","0.989: Positive sentiment\n","1.0: Positive sentiment\n","0.999: Positive sentiment\n","0.994: Positive sentiment\n","0.000768: Negative sentiment\n","9.74e-07: Negative sentiment\n","0.00105: Negative sentiment\n","0.996: Positive sentiment\n","0.99: Positive sentiment\n","0.986: Positive sentiment\n","0.00972: Negative sentiment\n","0.992: Positive sentiment\n","0.996: Positive sentiment\n","0.41: Negative sentiment\n","0.00114: Negative sentiment\n","1.0: Positive sentiment\n","0.998: Positive sentiment\n","1.0: Positive sentiment\n","0.997: Positive sentiment\n","0.996: Positive sentiment\n","0.952: Positive sentiment\n","0.00724: Negative sentiment\n","0.999: Positive sentiment\n","5.43e-06: Negative sentiment\n","0.00249: Negative sentiment\n","1.66e-07: Negative sentiment\n","1.0: Positive sentiment\n","1.0: Positive sentiment\n","0.248: Negative sentiment\n","0.975: Positive sentiment\n","0.657: Positive sentiment\n","1.0: Positive sentiment\n","0.939: Positive sentiment\n","0.0685: Negative sentiment\n","0.0096: Negative sentiment\n","0.991: Positive sentiment\n","0.995: Positive sentiment\n","0.122: Negative sentiment\n","0.853: Positive sentiment\n","0.98: Positive sentiment\n","0.00661: Negative sentiment\n","1.0: Positive sentiment\n","0.997: Positive sentiment\n","0.965: Positive sentiment\n","0.684: Positive sentiment\n","0.0298: Negative sentiment\n","0.847: Positive sentiment\n","0.0148: Negative sentiment\n","0.0276: Negative sentiment\n","0.0304: Negative sentiment\n","0.00627: Negative sentiment\n","Accuracy: 0.800000\n","Precision: 0.912281\n","Recall: 0.776119\n","F1 score: 0.838710\n","[[28  5]\n"," [15 52]]\n"],"name":"stdout"}]}]}