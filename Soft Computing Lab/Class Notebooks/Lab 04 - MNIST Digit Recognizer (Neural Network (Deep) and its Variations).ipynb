{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 04 - MNIST Digit Recognizer (Neural Network (Deep) and its Variations).ipynb","provenance":[{"file_id":"1rnBQkKvLaZN0_hSdoyNvmMU8vpCFscs3","timestamp":1614064718345},{"file_id":"1JXiP9YzF-roL3Vt2UOLYKsRYf2yauTRK","timestamp":1592642571900}],"collapsed_sections":[],"authorship_tag":"ABX9TyMl8gLhItOqJ54pG2kukN24"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b054b486fda9456fbd0e2d745608d441":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f01324cb460c486098df9334c24e5c76","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_53f6a7827ff94d9f9c25c7c8415c1e3d","IPY_MODEL_593164c0ddeb42a6bd884d71fc60c7dd"]}},"f01324cb460c486098df9334c24e5c76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"53f6a7827ff94d9f9c25c7c8415c1e3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5ec7a6248c68495f944940d0fecc9477","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f01dab3013e342a6a084d3f832235698"}},"593164c0ddeb42a6bd884d71fc60c7dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_007a08bf28e0471d8d315b11b01e8362","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:20&lt;00:00, 2889949.62it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e8d471867c0f455cb30ade6297c419f8"}},"5ec7a6248c68495f944940d0fecc9477":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f01dab3013e342a6a084d3f832235698":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"007a08bf28e0471d8d315b11b01e8362":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e8d471867c0f455cb30ade6297c419f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69c7fc319dff4be09d15e2b5edb51638":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_122102fa967344dea489d0f9ccd34b48","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_42d6aedb511f40f18193913f8563a8ca","IPY_MODEL_2c74f38d1d154f1fabf51441a5fb9147"]}},"122102fa967344dea489d0f9ccd34b48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"42d6aedb511f40f18193913f8563a8ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e1f6507b41844a6fb91875e1911d00dc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f6357073598546ba948d107065a912da"}},"2c74f38d1d154f1fabf51441a5fb9147":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a76b60f2129441feb6f24eb549ab7d30","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:03&lt;00:00, 9836.13it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d17f3a271fc542e998040917c1f3a255"}},"e1f6507b41844a6fb91875e1911d00dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f6357073598546ba948d107065a912da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a76b60f2129441feb6f24eb549ab7d30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d17f3a271fc542e998040917c1f3a255":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"851fd4bb7d474880a41352610b6589df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8ba754adad2047a2ba0a93e8efe4cbca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1aaa720d9e2646eea234eab170155de3","IPY_MODEL_56eb92ca3e674a8c99a99b8e98608300"]}},"8ba754adad2047a2ba0a93e8efe4cbca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1aaa720d9e2646eea234eab170155de3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_927584e5da1d42df93e7560eb98374c7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a55de3b6f0854b8689f6d9716db60008"}},"56eb92ca3e674a8c99a99b8e98608300":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c0c25553353247289d1c1eb7e11503f4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:02&lt;00:00, 616469.70it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e089b914047493f8d47499843a42914"}},"927584e5da1d42df93e7560eb98374c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a55de3b6f0854b8689f6d9716db60008":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0c25553353247289d1c1eb7e11503f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6e089b914047493f8d47499843a42914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57b391a507924ffa978b1edce49adae4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f6fe7de582154e679fba3c53e3c2c5ae","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e8b30e5552f5487ab9523729c86754b5","IPY_MODEL_e3b5e9dd085340cab9b2ee8289077703"]}},"f6fe7de582154e679fba3c53e3c2c5ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8b30e5552f5487ab9523729c86754b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_78c392ee44b746b3a00dc7744a9630f0","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e91d746ddbf54aad87440039c38d3828"}},"e3b5e9dd085340cab9b2ee8289077703":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_062f3168919345b5af5de4eb24ac1ab1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/4542 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5686532aeb6b4b94be2d085239198b9e"}},"78c392ee44b746b3a00dc7744a9630f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e91d746ddbf54aad87440039c38d3828":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"062f3168919345b5af5de4eb24ac1ab1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5686532aeb6b4b94be2d085239198b9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"z0tKD3f1Nt8y"},"source":["## MNIST Digit Recognizer (Neural Network)"]},{"cell_type":"markdown","metadata":{"id":"SyzBofWXmt0H"},"source":["\n","\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1VT-muG5HJoWaT9jwlmI6fe_7CjbW9x8I\" width=\"300\">\n","</div>\n","\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1foK0jI3dSuvCBBUbiqVKMiLn7x3ngA_x\" width=\"350\" height=\"200\">\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"7ILa4hbOxdnJ"},"source":["\r\n","## One Layer Neural Network with Sigmoid Activation"]},{"cell_type":"code","metadata":{"id":"HJ1dVc9mgbN8","executionInfo":{"status":"ok","timestamp":1614240508757,"user_tz":-360,"elapsed":4833,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o9vfh-4mtXt3"},"source":["<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=16ZWsh6DrrwuzC4stYhsmcpIEGCke33Jc\" width=\"480\">\n","</div>\n"]},{"cell_type":"markdown","metadata":{"id":"EL0F4kOtWER5"},"source":[" - Our input size is determined by the size of the image **(height x width) = (28X28)**. Hence the size of our input is **784 (28 x 28)**.\n","\n"," - When we pass an image to our model, it will try to predict if it's **0, 1, 2, 3, 4, 5, 6, 7, 8, or 9**. That is a total of 10 classes, hence we have an output size of 10.\n","\n"," - Determining the **hidden layer size** is one of the crutial part. This can be any **real number**. A large number of hidden nodes denotes a **bigger model with more parameters**. \n","\n","- The bigger model isn't **always the better model**. On the otner hand, bigger model requires **more training samples** to learn and converge to a good model. \n","\n","- Hence, it is wise to pick the model size for the problem at hand. Because it is a simple problem of recognizing digits, we typically would not need a big model to achieve good results.\n","\n","- Moreover, too small of a hidden size would mean there would be **insufficient model capacity to predict competently**. Too small of a capacity denotes a **smaller brain capacity** so no matter how many training samples you provide, it has a maximum capacity boundary in terms of its **predictive power**."]},{"cell_type":"markdown","metadata":{"id":"fXVIydDCxDPS"},"source":["- **Input dimension:**\n","  - Size of image: $28 \\times 28 = 784$\n","\n","- **Output dimension: 10**\n","  - 0, 1, 2, 3, 4, 5, 6, 7, 8, 9"]},{"cell_type":"code","metadata":{"id":"o5hVijghPqz0","executionInfo":{"status":"ok","timestamp":1614241502571,"user_tz":-360,"elapsed":1324,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}}},"source":["# Hyperparameters\n","\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100 # num of hidden nodes\n","output_dim = 10\n","\n","learning_rate = 0.1  # More power so we can learn faster! previously it was 0.001\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C4R6x4MvEsOT"},"source":["### Loading MNIST Dataset"]},{"cell_type":"code","metadata":{"id":"eUumuKA-cahD","colab":{"base_uri":"https://localhost:8080/","height":403,"referenced_widgets":["b054b486fda9456fbd0e2d745608d441","f01324cb460c486098df9334c24e5c76","53f6a7827ff94d9f9c25c7c8415c1e3d","593164c0ddeb42a6bd884d71fc60c7dd","5ec7a6248c68495f944940d0fecc9477","f01dab3013e342a6a084d3f832235698","007a08bf28e0471d8d315b11b01e8362","e8d471867c0f455cb30ade6297c419f8","69c7fc319dff4be09d15e2b5edb51638","122102fa967344dea489d0f9ccd34b48","42d6aedb511f40f18193913f8563a8ca","2c74f38d1d154f1fabf51441a5fb9147","e1f6507b41844a6fb91875e1911d00dc","f6357073598546ba948d107065a912da","a76b60f2129441feb6f24eb549ab7d30","d17f3a271fc542e998040917c1f3a255","851fd4bb7d474880a41352610b6589df","8ba754adad2047a2ba0a93e8efe4cbca","1aaa720d9e2646eea234eab170155de3","56eb92ca3e674a8c99a99b8e98608300","927584e5da1d42df93e7560eb98374c7","a55de3b6f0854b8689f6d9716db60008","c0c25553353247289d1c1eb7e11503f4","6e089b914047493f8d47499843a42914","57b391a507924ffa978b1edce49adae4","f6fe7de582154e679fba3c53e3c2c5ae","e8b30e5552f5487ab9523729c86754b5","e3b5e9dd085340cab9b2ee8289077703","78c392ee44b746b3a00dc7744a9630f0","e91d746ddbf54aad87440039c38d3828","062f3168919345b5af5de4eb24ac1ab1","5686532aeb6b4b94be2d085239198b9e"]},"executionInfo":{"status":"ok","timestamp":1614241589856,"user_tz":-360,"elapsed":8469,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"dc3e1e11-fbe6-4aed-cf1c-bafbf70e8ddd"},"source":["'''\n","LOADING DATASET\n","'''\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","'''\n","MAKING DATASET ITERABLE\n","'''\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)  "],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b054b486fda9456fbd0e2d745608d441","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69c7fc319dff4be09d15e2b5edb51638","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"851fd4bb7d474880a41352610b6589df","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57b391a507924ffa978b1edce49adae4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vmkMVvf8CLHf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614241591800,"user_tz":-360,"elapsed":1927,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"77d8c392-c0d1-427e-9a62-3b28feea96ff"},"source":["print(len(train_dataset))\n","print(len(test_dataset))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["60000\n","10000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Isz6lbl4Iovx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614241617597,"user_tz":-360,"elapsed":1212,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"d399a8f9-7ec7-487f-c3dd-b093e9f6f98e"},"source":["# One Image Size\n","print(train_dataset[0][0].size())\n","print(train_dataset[0][0].numpy().shape)\n","# First Image Label\n","print(train_dataset[0][1])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["torch.Size([1, 28, 28])\n","(1, 28, 28)\n","5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GQB8tvNUQZop"},"source":["<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1mn8G92moF0MqXhD0J-M7cPidCYXR0hHS\" width=\"680\" height=\"380\">\n","</div>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nRm3MYkW8QVU"},"source":["### Step #1 : Design your model using class"]},{"cell_type":"code","metadata":{"id":"6mydzEXpeu7G","executionInfo":{"status":"ok","timestamp":1614241854987,"user_tz":-360,"elapsed":1308,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}}},"source":["class NeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","\n","        ### Non-linearity\n","        self.sigmoid = nn.Sigmoid()\n","\n","        ### Output layer\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        # Linear layer\n","        out  = self.linear_1(x)\n","        # Non-linearity\n","        out = self.sigmoid(out)\n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIfiAaZB1rJz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614241875151,"user_tz":-360,"elapsed":10888,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"b38d6d11-01a4-4a1a-dc93-2ca1d146a743"},"source":["'''\n","INSTANTIATE MODEL CLASS\n","'''\n","model = NeuralNetworkModel(input_size = input_dim,\n","                           num_classes = output_dim,\n","                           num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NeuralNetworkModel(\n","  (linear_1): Linear(in_features=784, out_features=100, bias=True)\n","  (sigmoid): Sigmoid()\n","  (linear_out): Linear(in_features=100, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"pdrDJPOKzdSp"},"source":["###Step #2 : Construct loss and optimizer\n","\n","Unlike linear regression, we do not use **MSE** here, we need **Cross Entropy Loss** to calculate our loss before we backpropagate and update our parameters.\n","\n","`criterion = nn.CrossEntropyLoss() ` \n","\n","It does 2 things at the same time.\n","\n","1. Computes softmax ([Logistic or Sigmoid]/softmax function)\n","2. Computes Cross Entropy Loss"]},{"cell_type":"code","metadata":{"id":"GM2q_XGHzcta","executionInfo":{"status":"ok","timestamp":1614241875153,"user_tz":-360,"elapsed":3271,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}}},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2Hb_JQ6AUok"},"source":["###Step #3 : Training: forward, loss, backward, step"]},{"cell_type":"code","metadata":{"id":"Q3Jb4vhRZI9p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614241906367,"user_tz":-360,"elapsed":27954,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"0771caaf-456c-4505-bcaf-dadf8f917eba"},"source":["'''\n","TRAIN THE MODEL\n","'''\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.5571920871734619. Accuracy: 86.0\n","Iteration: 1000. Loss: 0.4421622157096863. Accuracy: 89.5\n","Iteration: 1500. Loss: 0.422754168510437. Accuracy: 90.5\n","Iteration: 2000. Loss: 0.5641263127326965. Accuracy: 91.21\n","Iteration: 2500. Loss: 0.3965786099433899. Accuracy: 91.55\n","Iteration: 3000. Loss: 0.27061140537261963. Accuracy: 92.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t_5UaSvBJckA"},"source":["## Expanding Neural Network variants\n","\n","**2 ways** to expand a neural network\n","- Different non-linear activation\n","- More hidden layers"]},{"cell_type":"markdown","metadata":{"id":"sG1A_uEHL5uU"},"source":["## One Layer Neural Network with Tanh Activation"]},{"cell_type":"code","metadata":{"id":"cyXyrgHMw41l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614242067794,"user_tz":-360,"elapsed":27719,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"bdcddea7-0a7a-4a42-dd6f-da6616a28011"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class NeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","\n","        ### Non-linearity\n","        self.tanh = nn.Tanh()\n","\n","        ### Output layer\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        # Linear layer\n","        out  = self.linear_1(x)\n","        # Non-linearity\n","        out = self.tanh(out)\n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","model = NeuralNetworkModel(input_size = input_dim,\n","                           num_classes = output_dim,\n","                           num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.214632049202919. Accuracy: 91.34\n","Iteration: 1000. Loss: 0.24148783087730408. Accuracy: 92.11\n","Iteration: 1500. Loss: 0.43570029735565186. Accuracy: 93.42\n","Iteration: 2000. Loss: 0.22971323132514954. Accuracy: 94.32\n","Iteration: 2500. Loss: 0.22221192717552185. Accuracy: 94.66\n","Iteration: 3000. Loss: 0.08887012302875519. Accuracy: 95.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hoxfWq6ZNPiL"},"source":["## One Layer Neural Network with ReLU Activation"]},{"cell_type":"code","metadata":{"id":"PGVrecUPMsyT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614242137804,"user_tz":-360,"elapsed":28346,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"60e3abc7-d3b3-46c6-fe44-181318b6d353"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class NeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","\n","        ### Non-linearity\n","        self.relu = nn.ReLU()\n","\n","        ### Output layer\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        # Linear layer\n","        out  = self.linear_1(x)\n","        # Non-linearity\n","        out = self.relu(out)\n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","model = NeuralNetworkModel(input_size = input_dim,\n","                           num_classes = output_dim,\n","                           num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.355338454246521. Accuracy: 88.59\n","Iteration: 1000. Loss: 0.1691860556602478. Accuracy: 92.94\n","Iteration: 1500. Loss: 0.13430403172969818. Accuracy: 94.01\n","Iteration: 2000. Loss: 0.23789997398853302. Accuracy: 94.71\n","Iteration: 2500. Loss: 0.09087537974119186. Accuracy: 95.46\n","Iteration: 3000. Loss: 0.16318005323410034. Accuracy: 95.67\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T_r9Lq-O0FJi"},"source":["## Two Layer Neural Network (Deep) with ReLU Activation"]},{"cell_type":"code","metadata":{"id":"YNhAoGbnNasI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614242385962,"user_tz":-360,"elapsed":28469,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"c4309e88-d25f-4dc8-e182-7a0d6e48c735"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 # num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class DeepNeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer: 784 --> 100\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","        ### Non-linearity in 1st hidden layer\n","        self.relu_1 = nn.ReLU()\n","\n","        ### 2nd hidden layer: 100 --> 100\n","        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n","        ### Non-linearity in 2nd hidden layer\n","        self.relu_2 = nn.ReLU()\n","\n","        ### Output layer: 100 --> 10\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        ### 1st hidden layer\n","        out  = self.linear_1(x)\n","        ### Non-linearity in 1st hidden layer\n","        out = self.relu_1(out)\n","        \n","        ### 2nd hidden layer\n","        out  = self.linear_2(out)\n","        ### Non-linearity in 2nd hidden layer\n","        out = self.relu_2(out)\n","        \n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","# INSTANTIATE MODEL CLASS\n","\n","model = DeepNeuralNetworkModel(input_size = input_dim,\n","                               num_classes = output_dim,\n","                               num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","# INSTANTIATE LOSS & OPTIMIZER CLASS\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.41489917039871216. Accuracy: 90.29\n","Iteration: 1000. Loss: 0.3434804677963257. Accuracy: 93.36\n","Iteration: 1500. Loss: 0.1742965131998062. Accuracy: 94.87\n","Iteration: 2000. Loss: 0.11172012984752655. Accuracy: 95.69\n","Iteration: 2500. Loss: 0.14843688905239105. Accuracy: 95.89\n","Iteration: 3000. Loss: 0.06709164381027222. Accuracy: 96.65\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JYdiRLt3FPLy"},"source":["## Three Layer Neural Network (Deep) with ReLU Activation"]},{"cell_type":"code","metadata":{"id":"T0jY7KZ0E50C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614242491916,"user_tz":-360,"elapsed":29631,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"51ddf27f-e8b8-48f3-c605-f57ae160db01"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","\n","# Hyperparameters\n","batch_size = 100\n","num_iters = 3000\n","input_dim = 28*28 #num_features = 784\n","num_hidden = 100\n","output_dim = 10\n","\n","learning_rate = 0.1\n","\n","# Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),  # Normalize the image to [0-1] from [0-255]\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())\n","\n","\n","num_epochs = num_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False) \n","\n","class DeepNeuralNetworkModel(nn.Module):\n","    def __init__(self, input_size, num_classes, num_hidden):\n","        super().__init__()\n","        ### 1st hidden layer: 784 --> 100\n","        self.linear_1 = nn.Linear(input_size, num_hidden)\n","        ### Non-linearity in 1st hidden layer\n","        self.relu_1 = nn.ReLU()\n","\n","        ### 2nd hidden layer: 100 --> 100\n","        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n","        ### Non-linearity in 2nd hidden layer\n","        self.relu_2 = nn.ReLU()\n","\n","        ### 3rd hidden layer: 100 --> 100\n","        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n","        ### Non-linearity in 3rd hidden layer\n","        self.relu_3 = nn.ReLU()\n","\n","        ### Output layer: 100 --> 10\n","        self.linear_out = nn.Linear(num_hidden, num_classes)\n","\n","    def forward(self, x):\n","        ### 1st hidden layer\n","        out  = self.linear_1(x)\n","        ### Non-linearity in 1st hidden layer\n","        out = self.relu_1(out)\n","        \n","        ### 2nd hidden layer\n","        out  = self.linear_2(out)\n","        ### Non-linearity in 2nd hidden layer\n","        out = self.relu_2(out)\n","\n","        ### 3rd hidden layer\n","        out  = self.linear_3(out)\n","        ### Non-linearity in 3rd hidden layer\n","        out = self.relu_3(out)\n","        \n","        # Linear layer (output)\n","        probas  = self.linear_out(out)\n","        return probas\n","\n","# INSTANTIATE MODEL CLASS\n","\n","model = DeepNeuralNetworkModel(input_size = input_dim,\n","                               num_classes = output_dim,\n","                               num_hidden = num_hidden)\n","# To enable GPU\n","model.to(device)\n","\n","# INSTANTIATE LOSS & OPTIMIZER CLASS\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        images = images.view(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images) \n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","               \n","                images = images.view(-1, 28*28).to(device)\n","\n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","\n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs, 1)\n","\n","                # Total number of labels\n","                total += labels.size(0)\n","\n","\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum() \n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            accuracy = 100 * correct.item() / total\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.44121184945106506. Accuracy: 90.28\n","Iteration: 1000. Loss: 0.16526439785957336. Accuracy: 94.02\n","Iteration: 1500. Loss: 0.3894992172718048. Accuracy: 93.6\n","Iteration: 2000. Loss: 0.13394795358181. Accuracy: 96.22\n","Iteration: 2500. Loss: 0.050842948257923126. Accuracy: 96.5\n","Iteration: 3000. Loss: 0.0751292034983635. Accuracy: 97.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-1vTvfpkNjHL"},"source":["## What's Next?\n","\n","- Try with other activations from Pytorch. [**LINK**](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n","- Try different activations for **different layers** (We used ReLU Only)\n","- Try adding more hidden layers. \n","- Try increasing the hidden layer neurons (***We used 100 here in this example***)\n","- Try experimenting with different neurons for different hidden layers (We here in this examples used **a fixed sixe: 100**)\n","\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1VYlYjGEYo6JKsiADnzOCNM2TPkhNI-Yq\" width=\"230\" height=\"580\">\n","</div>\n","\n","<div align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1hMrKBdhQ8cmhxGgCzFczQi4xpHMsHufD\" width=\"680\" height=\"280\">\n","</div>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mx_2yr0wwRju"},"source":["# **Assignment #2**\r\n","\r\n","- Use this notebook text section to present any description of the approach, models, figures, tables, and equation where necessary. \r\n","- Try different settings ***(Exactly 4)*** of the hyperparameters to show incremental progress in terms of the accuracy for both the problems. You can use markdown tables to present the results. \r\n","- For both the problems, split the training set to **90%** and test set to **10%**. That means a **90:10** ratio. \r\n","\r\n","**Sample markdown table:-**\r\n","\r\n","| Column 1       | Column 2     | Column 3     |\r\n","| :------------- | :----------: | -----------: |\r\n","|  Cell Contents | More Stuff   | And Again    |\r\n","| You Can Also   | Put Pipes In | Like this \\| |\r\n","\r\n","\r\n","## **NumtaDB: Bengali Handwritten Digits**\r\n","\r\n","**Dataset Link:** https://www.kaggle.com/BengaliAI/numta/\r\n","\r\n","**Snapshot from NumtaDB**\r\n","\r\n","<div align=\"center\">\r\n","<img src=\"https://drive.google.com/uc?id=1LvkNwV1My2RniR_JsbasBET1fa97eMQu\" width=\"500\">\r\n","</div>\r\n","\r\n","### **Problem #1**\r\n","\r\n","*   Apply **Neural Network / Deep Neural Network** for the **NumtaDB** dataset and build a multiclass classification model that can recognize `[0-9]` Bengali handwritten digits with different hyperparameter settings.  \r\n","\r\n","## **Ekush Bengali Handwritten Digits**\r\n","\r\n","**Dataset Link:** https://shahariarrabby.github.io/ekush/#home\r\n","\r\n","**Snapshot from Ekush**\r\n","\r\n","<div align=\"center\">\r\n","<img src=\"https://drive.google.com/uc?id=1GhuJfYchOjfNoBtwkpWivPRQinegMYwy\" width=\"600\">\r\n","</div>\r\n","\r\n","### **Problem #2**\r\n","\r\n","*   Apply **Neural Network / Deep Neural Network** for the **Ekush** dataset and build a binary classification model that can predict  **male/female** from Bengali handwritten digits with different hyperparameter settings.  \r\n","\r\n","**Problem Portion Dataset Link:** https://shahariarrabby.github.io/ekush/#download\r\n","\r\n","\r\n","# **Deadline: 7 March 2021**\r\n","\r\n","### **Notes:-**\r\n","\r\n"," - Don't try to copy code from others. \r\n"," - No extension of the deadline will be granted! \r\n"]}]}