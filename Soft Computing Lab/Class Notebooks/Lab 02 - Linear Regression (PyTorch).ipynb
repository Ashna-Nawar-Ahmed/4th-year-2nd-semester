{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 02 - Linear Regression (PyTorch).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPb0rbfN96V6dNnJK5P25cl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"smmQiJ_7pFr2"},"source":["## Linear Regression\r\n","\r\n","### PyTorch Model Designing Steps\r\n","\r\n","1.   **Design your model using class with Variables**\r\n","2.   **Construct loss and optimizer  (select from PyTorch API)**\r\n","3.   **Training cycle (forward, backward, update)**"]},{"cell_type":"markdown","metadata":{"id":"QMrLzV3JpNuz"},"source":["### Step #1 : Design your model using class with Variables"]},{"cell_type":"code","metadata":{"id":"AYTP7m75o9Cx"},"source":["from torch import nn\r\n","import torch\r\n","from torch import tensor\r\n","\r\n","import matplotlib.pyplot as plt\r\n","\r\n","x_data = tensor([[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]])\r\n","y_data = tensor([[2.0], [4.0], [6.0], [8.0], [10.0], [12.0]])\r\n","\r\n","# Hyper-parameters\r\n","input_size = 1\r\n","output_size = 1\r\n","num_epochs = 100\r\n","learning_rate = 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9vKIOIppSHo","executionInfo":{"status":"ok","timestamp":1611995733527,"user_tz":-360,"elapsed":4545,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"1a53b295-da53-4eda-f966-31016f77c4d1"},"source":["print(torch.__version__)\r\n","\r\n","print(torch.cuda.get_device_name())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.7.0+cu101\n","Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A8nkKlBFpUa_"},"source":["### Using GPU for the PyTorch Models\r\n","\r\n","Remember always 2 things must be on GPU\r\n","\r\n","- model\r\n","- tensors"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TEshzKwPpVKK","executionInfo":{"status":"ok","timestamp":1611995743897,"user_tz":-360,"elapsed":14896,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"83f11f0e-3706-4518-ebc3-bc2dbbc9a6b2"},"source":["class Model(nn.Module):\r\n","    def __init__(self):\r\n","        \"\"\"\r\n","        In the constructor we instantiate nn.Linear module\r\n","        \"\"\"\r\n","        super().__init__()\r\n","        self.linear = torch.nn.Linear(input_size, output_size)  # One in and one out\r\n","\r\n","    def forward(self, x):\r\n","        \"\"\"\r\n","        In the forward function we accept a Variable of input data and we must return\r\n","        a Variable of output data. We can use Modules defined in the constructor as\r\n","        well as arbitrary operators on Variables.\r\n","        \"\"\"\r\n","        y_pred = self.linear(x)\r\n","        return y_pred\r\n","\r\n","\r\n","# our model\r\n","model = Model()\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n","model.to(device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (linear): Linear(in_features=1, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"hzpD5NXGpZqB"},"source":["### Explanations:- \r\n","\r\n","`torch.nn.Linear(in_features, out_features, bias=True)`\r\n","\r\n","Applies a linear transformation to the incoming data: $y = W^T * x + b$\r\n","\r\n","**Parameters:**\r\n","\r\n","- `in_features `– size of each input sample (i.e. size of x)\r\n","- `out_features` – size of each output sample (i.e. size of y)\r\n","- `bias` – If set to False, the layer will not learn an additive bias. **Default: True**\r\n"]},{"cell_type":"markdown","metadata":{"id":"OBZ_74UWpdva"},"source":["###Step #2 : Construct loss and optimizer (select from PyTorch API)"]},{"cell_type":"code","metadata":{"id":"80fAcWSKpgx6"},"source":["# Construct our loss function and an Optimizer. The call to model.parameters()\r\n","# in the SGD constructor will contain the learnable parameters\r\n","criterion = torch.nn.MSELoss(reduction='sum')\r\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DK1bP6cupi_y"},"source":["### Explanations:- \r\n","\r\n","MSE Loss: Mean Squared Error (**Default: 'mean'**)\r\n","\r\n","- $\\hat y$ :  prediction\r\n","- $y$ :  true value\r\n","\r\n","$MSE \\ (sum) =  \\sum_{i=1}^n(\\hat y_i - y_i)^2$\r\n","\r\n","$MSE \\ (mean) = \\frac{1}{n} \\sum_{i=1}^n(\\hat y_i - y_i)^2$"]},{"cell_type":"markdown","metadata":{"id":"kuuRYS_5pmjs"},"source":["###Step #3 : Training: forward, loss, backward, step"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9iK4HJ7ypn8i","executionInfo":{"status":"ok","timestamp":1611995798266,"user_tz":-360,"elapsed":1207,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"fcb4354c-6256-4174-c11a-7173cc73c4dd"},"source":["# Credit: https://github.com/jcjohnson/pytorch-examples\r\n","\r\n","# Training loop\r\n","for epoch in range(num_epochs):\r\n","    # 1) Forward pass: Compute predicted y by passing x to the model\r\n","    y_pred = model(x_data.to(device))\r\n","\r\n","    # 2) Compute and print loss\r\n","    loss = criterion(y_pred, y_data.to(device))\r\n","    print(f'Epoch: {epoch} | Loss: {loss.item()} ')\r\n","\r\n","    # Zero gradients, perform a backward pass, and update the weights.\r\n","    optimizer.zero_grad()\r\n","    # Getting gradients w.r.t. parameters\r\n","    loss.backward()\r\n","    # Updating parameters\r\n","    optimizer.step()\r\n","\r\n","\r\n","# After training\r\n","hour_var = tensor([[7.0]]).to(device)\r\n","y_pred = model(hour_var)\r\n","print(\"Prediction (after training)\",  7, model(hour_var).data[0][0].item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 0 | Loss: 0.04414632171392441 \n","Epoch: 1 | Loss: 0.037211932241916656 \n","Epoch: 2 | Loss: 0.03136666119098663 \n","Epoch: 3 | Loss: 0.02643958479166031 \n","Epoch: 4 | Loss: 0.022286424413323402 \n","Epoch: 5 | Loss: 0.01878545433282852 \n","Epoch: 6 | Loss: 0.015834316611289978 \n","Epoch: 7 | Loss: 0.013346947729587555 \n","Epoch: 8 | Loss: 0.011250494979321957 \n","Epoch: 9 | Loss: 0.00948311947286129 \n","Epoch: 10 | Loss: 0.007993534207344055 \n","Epoch: 11 | Loss: 0.006737751420587301 \n","Epoch: 12 | Loss: 0.005679425783455372 \n","Epoch: 13 | Loss: 0.00478725228458643 \n","Epoch: 14 | Loss: 0.004035332705825567 \n","Epoch: 15 | Loss: 0.0034015250857919455 \n","Epoch: 16 | Loss: 0.0028671536128968 \n","Epoch: 17 | Loss: 0.002416762989014387 \n","Epoch: 18 | Loss: 0.002037121681496501 \n","Epoch: 19 | Loss: 0.001717082574032247 \n","Epoch: 20 | Loss: 0.0014473588671535254 \n","Epoch: 21 | Loss: 0.0012200772762298584 \n","Epoch: 22 | Loss: 0.0010285326279699802 \n","Epoch: 23 | Loss: 0.0008669731905683875 \n","Epoch: 24 | Loss: 0.0007308223284780979 \n","Epoch: 25 | Loss: 0.0006160807679407299 \n","Epoch: 26 | Loss: 0.0005193640245124698 \n","Epoch: 27 | Loss: 0.0004377948062028736 \n","Epoch: 28 | Loss: 0.00036905714659951627 \n","Epoch: 29 | Loss: 0.00031109602423384786 \n","Epoch: 30 | Loss: 0.0002622445463202894 \n","Epoch: 31 | Loss: 0.00022103048104327172 \n","Epoch: 32 | Loss: 0.00018631585408002138 \n","Epoch: 33 | Loss: 0.00015708355931565166 \n","Epoch: 34 | Loss: 0.00013243967259768397 \n","Epoch: 35 | Loss: 0.0001116378916776739 \n","Epoch: 36 | Loss: 9.413070802111179e-05 \n","Epoch: 37 | Loss: 7.938130875118077e-05 \n","Epoch: 38 | Loss: 6.693360774079338e-05 \n","Epoch: 39 | Loss: 5.643032636726275e-05 \n","Epoch: 40 | Loss: 4.7579771489836276e-05 \n","Epoch: 41 | Loss: 4.012114368379116e-05 \n","Epoch: 42 | Loss: 3.3833723136922345e-05 \n","Epoch: 43 | Loss: 2.8520098567241803e-05 \n","Epoch: 44 | Loss: 2.4056535039562732e-05 \n","Epoch: 45 | Loss: 2.0292434783186764e-05 \n","Epoch: 46 | Loss: 1.7130943888332695e-05 \n","Epoch: 47 | Loss: 1.4457059478445444e-05 \n","Epoch: 48 | Loss: 1.2199224329378922e-05 \n","Epoch: 49 | Loss: 1.0295959327777382e-05 \n","Epoch: 50 | Loss: 8.68849383550696e-06 \n","Epoch: 51 | Loss: 7.3387905104027595e-06 \n","Epoch: 52 | Loss: 6.202298209245782e-06 \n","Epoch: 53 | Loss: 5.237749519437784e-06 \n","Epoch: 54 | Loss: 4.4233556764083914e-06 \n","Epoch: 55 | Loss: 3.7351574064814486e-06 \n","Epoch: 56 | Loss: 3.1560714432998793e-06 \n","Epoch: 57 | Loss: 2.668224851731793e-06 \n","Epoch: 58 | Loss: 2.257534788441262e-06 \n","Epoch: 59 | Loss: 1.913428150146501e-06 \n","Epoch: 60 | Loss: 1.6214072502407362e-06 \n","Epoch: 61 | Loss: 1.3771661997452611e-06 \n","Epoch: 62 | Loss: 1.1682066087814746e-06 \n","Epoch: 63 | Loss: 9.905502338369843e-07 \n","Epoch: 64 | Loss: 8.425095643360692e-07 \n","Epoch: 65 | Loss: 7.173612743827107e-07 \n","Epoch: 66 | Loss: 6.105864258643123e-07 \n","Epoch: 67 | Loss: 5.207971867093875e-07 \n","Epoch: 68 | Loss: 4.4541320676216856e-07 \n","Epoch: 69 | Loss: 3.8081543607404456e-07 \n","Epoch: 70 | Loss: 3.2628258850309066e-07 \n","Epoch: 71 | Loss: 2.807912551361369e-07 \n","Epoch: 72 | Loss: 2.4094634909488377e-07 \n","Epoch: 73 | Loss: 2.0819703649976873e-07 \n","Epoch: 74 | Loss: 1.800950144570379e-07 \n","Epoch: 75 | Loss: 1.5580013723592856e-07 \n","Epoch: 76 | Loss: 1.3530416254070587e-07 \n","Epoch: 77 | Loss: 1.1766678653657436e-07 \n","Epoch: 78 | Loss: 1.0277517503709532e-07 \n","Epoch: 79 | Loss: 9.065848871614435e-08 \n","Epoch: 80 | Loss: 8.004781193449162e-08 \n","Epoch: 81 | Loss: 7.053864692352363e-08 \n","Epoch: 82 | Loss: 6.230408189367154e-08 \n","Epoch: 83 | Loss: 5.544825398828834e-08 \n","Epoch: 84 | Loss: 4.978483048034832e-08 \n","Epoch: 85 | Loss: 4.4602586513065035e-08 \n","Epoch: 86 | Loss: 4.0317047478310997e-08 \n","Epoch: 87 | Loss: 3.653326530184131e-08 \n","Epoch: 88 | Loss: 3.3295236789854243e-08 \n","Epoch: 89 | Loss: 3.051195562875364e-08 \n","Epoch: 90 | Loss: 2.799265530484263e-08 \n","Epoch: 91 | Loss: 2.564371470725746e-08 \n","Epoch: 92 | Loss: 2.373735696892254e-08 \n","Epoch: 93 | Loss: 2.1766993540950352e-08 \n","Epoch: 94 | Loss: 2.0134905298618833e-08 \n","Epoch: 95 | Loss: 1.8830178305506706e-08 \n","Epoch: 96 | Loss: 1.7476622815593146e-08 \n","Epoch: 97 | Loss: 1.637459945413866e-08 \n","Epoch: 98 | Loss: 1.544805172670749e-08 \n","Epoch: 99 | Loss: 1.4453007679549046e-08 \n","Prediction (after training) 7 13.99990463256836\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s4-xxwChptDd"},"source":["### Explanations:- \r\n","\r\n","- Calling `.backward()` mutiple times accumulates the gradient (**by addition**) for each parameter. \r\n","\r\n","- This is why you should call `optimizer.zero_grad()` after each .step() call. \r\n","\r\n","- Note that following the first `.backward` call, a second call is only possible after you have performed another **forward pass**.\r\n","\r\n","- `optimizer.step` performs a parameter update based on the current gradient (**stored in .grad attribute of a parameter**)\r\n","\r\n","### Simplified equation:-\r\n","\r\n","- `parameters = parameters - learning_rate * parameters_gradients`\r\n","- parameters $W$ and $b$ in ($y = W^T * x + b$)\r\n","- $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta$  [ General parameter $\\theta$ ]\r\n","  *  $\\theta$ : parameters (our variables)\r\n","  *  $\\eta$ : learning rate (how fast we want to learn)\r\n","  *  $\\nabla_\\theta$ : parameters' gradients\r\n","\r\n","  "]},{"cell_type":"markdown","metadata":{"id":"4-QxhMyVpwpI"},"source":["### Plot of predicted and actual values"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"63PO5rFcpzIs","executionInfo":{"status":"ok","timestamp":1611996095889,"user_tz":-360,"elapsed":1949,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"b6bcf2d0-2fba-4cc5-c1ac-81f587d58e6e"},"source":["# Clear figure\r\n","plt.clf()\r\n","\r\n","# Get predictions\r\n","predictions = model(x_data.to(device)).cpu().detach().numpy()\r\n","\r\n","# Plot true data\r\n","plt.plot(x_data, y_data, 'go', label='True data', alpha=0.5)\r\n","\r\n","# Plot predictions\r\n","plt.plot(x_data, predictions, '--', label='Predictions', alpha=0.5)\r\n","\r\n","# Legend and plot\r\n","plt.legend(loc='best')\r\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"9CNdLbXdp1qf"},"source":["### Saving Model to Directory "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i8gOmlqEp2pL","executionInfo":{"status":"ok","timestamp":1611996583856,"user_tz":-360,"elapsed":1190,"user":{"displayName":"Mir Tafseer Nayeem","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiM4cOpMNCedgjDWZ9oHIKufBTjojcruiTtinn=s64","userId":"11387451028968277735"}},"outputId":"fd5c5c61-ad88-4e8c-a260-1bbf89f1d3e8"},"source":["from google.colab import drive\r\n","\r\n","drive.mount('/content/gdrive')\r\n","\r\n","root_path = '/content/gdrive/My Drive/AUST Docs/AUST Teaching Docs/AUST Spring 2020/CSE 4238/Lab 02/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SGQYTPeHp7Ps"},"source":["### Save Model"]},{"cell_type":"code","metadata":{"id":"OLz98ZOMp-a0"},"source":["save_model = True\r\n","\r\n","if save_model is True:\r\n","    # Saves only parameters\r\n","    # wights & biases\r\n","    torch.save(model.state_dict(), root_path + 'linear_regression.pkl') \r\n","\r\n","# Save the model checkpoint \r\n","# torch.save(model.state_dict(), root_path + 'linear_regression.ckpt')\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ozaCVVkqqEjn"},"source":["### Load Model"]},{"cell_type":"code","metadata":{"id":"7QH6KiJhqFhL"},"source":["load_model = True\r\n","\r\n","if load_model is True:\r\n","    model.load_state_dict(torch.load(root_path + 'linear_regression.pkl'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oGH_TyhAqJrm"},"source":["### Try Other Optimizers\r\n","\r\n","- torch.optim.Adagrad\r\n","- torch.optim.Adam\r\n","- torch.optim.Adamax\r\n","- torch.optim.ASGD\r\n","- torch.optim.LBFGS\r\n","- torch.optim.RMSprop\r\n","- torch.optim.Rprop\r\n","- torch.optim.SGD\r\n"]},{"cell_type":"markdown","metadata":{"id":"djoJBKHDqMfi"},"source":["### *** Official PyTorch Tutorials ***\r\n","\r\n","https://pytorch.org/tutorials/"]}]}